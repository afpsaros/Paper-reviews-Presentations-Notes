\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\bibstyle{biblatex}
\bibdata{Evidential_classification-regression-blx,refs}
\citation{biblatex-control}
\abx@aux@refcontext{nyt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Parameter estimation}{2}{section.1}\protected@file@percent }
\newlabel{sec:estimation}{{1}{2}{Parameter estimation}{section.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Bernoulli/Categorical distribution}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Gaussian distribution}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Bayesian inference}{3}{subsection.1.3}\protected@file@percent }
\newlabel{eq:posterior}{{5}{3}{Bayesian inference}{equation.1.5}{}}
\citation{bishop2006pattern}
\abx@aux@cite{bishop2006pattern}
\abx@aux@segm{0}{0}{bishop2006pattern}
\citation{bishop2006pattern}
\abx@aux@cite{bishop2006pattern}
\abx@aux@segm{0}{0}{bishop2006pattern}
\abx@aux@page{2}{4}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Prior/Posterior predictive}{4}{subsection.1.4}\protected@file@percent }
\newlabel{eq:prior:predictive}{{7}{4}{Prior/Posterior predictive}{equation.1.7}{}}
\newlabel{eq:prior:predictive:2}{{8}{4}{Prior/Posterior predictive}{equation.1.8}{}}
\newlabel{eq:prior:predictive:dirichlet}{{9}{4}{Prior/Posterior predictive}{equation.1.9}{}}
\newlabel{eq:prior:predictive:nig}{{10}{4}{Prior/Posterior predictive}{equation.1.10}{}}
\newlabel{eq:posterior:predictive}{{11}{4}{Prior/Posterior predictive}{equation.1.11}{}}
\newlabel{eq:posterior:predictive:2}{{12}{5}{Prior/Posterior predictive}{equation.1.12}{}}
\newlabel{eq:marginal:likelihood}{{13}{5}{Prior/Posterior predictive}{equation.1.13}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Prior hyperparameters as fictitious evidence}{5}{subsection.1.5}\protected@file@percent }
\newlabel{sec:fictitious:evidence}{{1.5}{5}{Prior hyperparameters as fictitious evidence}{subsection.1.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Why the introduction}{5}{subsection.1.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Classification/Regression}{6}{section.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Problem description}{6}{subsection.2.1}\protected@file@percent }
\newlabel{eq:class:likelihood}{{14}{6}{Problem description}{equation.2.14}{}}
\newlabel{eq:regression:likelihood}{{15}{6}{Problem description}{equation.2.15}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Bayesian treatment}{7}{subsection.2.2}\protected@file@percent }
\newlabel{eq:posterior:predictive:mc}{{16}{7}{Bayesian treatment}{equation.2.16}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Interpretation of Bayesian regression estimates.\relax }}{7}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:bayes:regression}{{1}{7}{Interpretation of Bayesian regression estimates.\relax }{table.caption.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Evidential treatment}{8}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Introduction}{8}{subsubsection.2.3.1}\protected@file@percent }
\newlabel{sec:evidential:intro}{{2.3.1}{8}{Introduction}{subsubsection.2.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Making predictions}{8}{subsubsection.2.3.2}\protected@file@percent }
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Interpretation of evidential regression output.\relax }}{9}{table.caption.2}\protected@file@percent }
\newlabel{tab:evidential:regression}{{2}{9}{Interpretation of evidential regression output.\relax }{table.caption.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Standard vs evidential NN outputs.\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:standard:vs:evidential}{{1}{9}{Standard vs evidential NN outputs.\relax }{figure.caption.3}{}}
\abx@aux@page{4}{9}
\citation{sensoy2018evidential}
\abx@aux@cite{sensoy2018evidential}
\abx@aux@segm{0}{0}{sensoy2018evidential}
\citation{sensoy2018evidential}
\abx@aux@cite{sensoy2018evidential}
\abx@aux@segm{0}{0}{sensoy2018evidential}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces According to the original paper \textcite {amini2020deep}, the evidential distribution (the prior predictive) can be construed as a higher-order distribution on top of the unknown lower-order likelihood distribution from which observations are drawn. As depicted in part A of the figure, different values of fictitious evidence output by the NN correspond to different higher-order distributions. And based on NN-predicted higher-order distribution (part B), different likelihood functions can be drawn as shown in part C.\relax }}{10}{figure.caption.4}\protected@file@percent }
\newlabel{fig:evidential:distribution}{{2}{10}{According to the original paper \textcite {amini2020deep}, the evidential distribution (the prior predictive) can be construed as a higher-order distribution on top of the unknown lower-order likelihood distribution from which observations are drawn. As depicted in part A of the figure, different values of fictitious evidence output by the NN correspond to different higher-order distributions. And based on NN-predicted higher-order distribution (part B), different likelihood functions can be drawn as shown in part C.\relax }{figure.caption.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Loss function for evidential learning}{10}{subsubsection.2.3.3}\protected@file@percent }
\newlabel{eq:evidential:loss}{{18}{10}{Loss function for evidential learning}{equation.2.18}{}}
\citation{sensoy2018evidential}
\abx@aux@cite{sensoy2018evidential}
\abx@aux@segm{0}{0}{sensoy2018evidential}
\citation{sensoy2018evidential}
\abx@aux@cite{sensoy2018evidential}
\abx@aux@segm{0}{0}{sensoy2018evidential}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\abx@aux@page{8}{11}
\abx@aux@page{10}{11}
\abx@aux@page{11}{11}
\abx@aux@page{13}{11}
\newlabel{eq:evidential:regularizer}{{19}{11}{Loss function for evidential learning}{equation.2.19}{}}
\abx@aux@page{15}{11}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Summary}{11}{subsection.2.4}\protected@file@percent }
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\citation{amini2020deep}
\abx@aux@cite{amini2020deep}
\abx@aux@segm{0}{0}{amini2020deep}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Evidential vs standard regression.\relax }}{12}{table.caption.5}\protected@file@percent }
\newlabel{table:summary}{{3}{12}{Evidential vs standard regression.\relax }{table.caption.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Key points through examples}{12}{section.3}\protected@file@percent }
\abx@aux@page{17}{12}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Inference speed comparison for the depth estimation regression problem. See more info in \textcite {amini2020deep}.\relax }}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:inference:speed}{{3}{12}{Inference speed comparison for the depth estimation regression problem. See more info in \textcite {amini2020deep}.\relax }{figure.caption.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Effect of regularization for the cubic function regression problem.\relax }}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:regularization}{{4}{13}{Effect of regularization for the cubic function regression problem.\relax }{figure.caption.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Total uncertainty comparison for the cubic function regression problem.\relax }}{13}{figure.caption.8}\protected@file@percent }
\newlabel{fig:uncertainty}{{5}{13}{Total uncertainty comparison for the cubic function regression problem.\relax }{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Accuracy and uncertainty comparison for benchmark regression problems.\relax }}{13}{figure.caption.9}\protected@file@percent }
\newlabel{fig:accuracy}{{6}{13}{Accuracy and uncertainty comparison for benchmark regression problems.\relax }{figure.caption.9}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Disentangled uncertainty for the cubic function regression problem with more added noise towards the center of the in-distribution region. Predicted aleatoric uncertainty increases in the middle (as it should) and predicted epistemic uncertainty increases where there is no data (as it should).\relax }}{14}{figure.caption.10}\protected@file@percent }
\newlabel{fig:disentangled}{{7}{14}{Disentangled uncertainty for the cubic function regression problem with more added noise towards the center of the in-distribution region. Predicted aleatoric uncertainty increases in the middle (as it should) and predicted epistemic uncertainty increases where there is no data (as it should).\relax }{figure.caption.10}{}}
\abx@aux@read@bbl@mdfivesum{53346C50AE3A966A638731FB0694F7FC}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{amini2020deep}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{bishop2006pattern}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{sensoy2018evidential}{nyt/global//global/global}
\abx@aux@defaultlabelprefix{0}{amini2020deep}{}
\abx@aux@defaultlabelprefix{0}{bishop2006pattern}{}
\abx@aux@defaultlabelprefix{0}{sensoy2018evidential}{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{References}{15}{figure.caption.10}\protected@file@percent }
\abx@aux@page{20}{15}
\abx@aux@page{21}{15}
\abx@aux@page{22}{15}
\gdef \@abspage@last{15}
